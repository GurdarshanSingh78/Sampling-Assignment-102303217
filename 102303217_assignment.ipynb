{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOlptq4eLTME",
        "outputId": "d4948c11-e2ea-4f15-d533-6c9183a36fc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Balanced Data Shape: (1526, 31)\n",
            "Class Distribution:\n",
            "Class\n",
            "0    763\n",
            "1    763\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Calculated Sample Size (n): 385\n",
            "\n",
            "Samples created successfully!\n",
            "Simple Random Sample Size: 385\n",
            "Systematic Sample Size: 385\n",
            "Stratified Sample Size: 385\n",
            "Cluster Sample Size: 388\n",
            "Bootstrap Sample Size: 385\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "data = pd.read_csv('Creditcard_data.csv')\n",
        "\n",
        "class_0 = data[data['Class'] == 0]\n",
        "class_1 = data[data['Class'] == 1]\n",
        "\n",
        "class_1_over = class_1.sample(len(class_0), replace=True, random_state=42)\n",
        "balanced_data = pd.concat([class_0, class_1_over], axis=0)\n",
        "\n",
        "print(f\"New Balanced Data Shape: {balanced_data.shape}\")\n",
        "print(f\"Class Distribution:\\n{balanced_data['Class'].value_counts()}\")\n",
        "\n",
        "Z = 1.96\n",
        "p = 0.5\n",
        "E = 0.05\n",
        "\n",
        "n = math.ceil((Z**2 * p * (1 - p)) / (E**2))\n",
        "print(f\"\\nCalculated Sample Size (n): {n}\")\n",
        "\n",
        "samples = {}\n",
        "\n",
        "samples['Simple Random'] = balanced_data.sample(n=n, random_state=42)\n",
        "\n",
        "k = int(len(balanced_data) / n)\n",
        "indices = np.arange(0, len(balanced_data), k)[:n]\n",
        "samples['Systematic'] = balanced_data.iloc[indices]\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "stratified_sample, _ = train_test_split(\n",
        "    balanced_data,\n",
        "    train_size=n,\n",
        "    stratify=balanced_data['Class'],\n",
        "    random_state=42\n",
        ")\n",
        "samples['Stratified'] = stratified_sample\n",
        "\n",
        "balanced_data_cluster = balanced_data.copy()\n",
        "num_clusters = len(balanced_data) // 20\n",
        "balanced_data_cluster['cluster_id'] = np.random.randint(0, num_clusters, size=len(balanced_data))\n",
        "\n",
        "unique_clusters = balanced_data_cluster['cluster_id'].unique()\n",
        "selected_clusters = np.random.choice(\n",
        "    unique_clusters,\n",
        "    size=int(len(unique_clusters) * 0.25),\n",
        "    replace=False\n",
        ")\n",
        "cluster_sample = balanced_data_cluster[\n",
        "    balanced_data_cluster['cluster_id'].isin(selected_clusters)\n",
        "]\n",
        "samples['Cluster'] = cluster_sample.drop(columns=['cluster_id'])\n",
        "\n",
        "samples['Bootstrap'] = balanced_data.sample(n=n, replace=True, random_state=42)\n",
        "\n",
        "print(\"\\nSamples created successfully!\")\n",
        "for name, df in samples.items():\n",
        "    print(f\"{name} Sample Size: {len(df)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "\n",
        "models = {\n",
        "    'M1 (Logistic Regression)': LogisticRegression(random_state=42, max_iter=1000),\n",
        "    'M2 (Decision Tree)': DecisionTreeClassifier(random_state=42),\n",
        "    'M3 (Random Forest)': RandomForestClassifier(random_state=42),\n",
        "    'M4 (SVM)': SVC(random_state=42),\n",
        "    'M5 (KNN)': KNeighborsClassifier()\n",
        "}\n",
        "\n",
        "X = balanced_data.drop('Class', axis=1)\n",
        "y = balanced_data['Class']\n",
        "_, X_test, _, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "\n",
        "results = {}\n",
        "\n",
        "print(\"Training models...\\n\")\n",
        "\n",
        "for sample_name, sample_df in samples.items():\n",
        "    print(f\"Processing {sample_name}...\")\n",
        "\n",
        "    X_train = sample_df.drop('Class', axis=1)\n",
        "    y_train = sample_df['Class']\n",
        "\n",
        "    sample_scores = {}\n",
        "\n",
        "    for model_name, model in models.items():\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "        acc = accuracy_score(y_test, y_pred)\n",
        "        sample_scores[model_name] = round(acc * 100, 2)\n",
        "\n",
        "    results[sample_name] = sample_scores\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "print(\"       FINAL ACCURACY RESULTS (%)         \")\n",
        "print(results_df)\n",
        "\n",
        "results_df.to_csv(\"sampling_accuracy_table.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xwoCWo5Mbtk",
        "outputId": "bd1dfc98-9d6b-4137-c423-94c03281d8aa"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training models...\n",
            "\n",
            "Processing Simple Random...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Systematic...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Stratified...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Cluster...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Bootstrap...\n",
            "       FINAL ACCURACY RESULTS (%)         \n",
            "                          Simple Random  Systematic  Stratified  Cluster  \\\n",
            "M1 (Logistic Regression)          92.41       86.91       89.27    91.36   \n",
            "M2 (Decision Tree)               100.00       99.48       97.38    99.48   \n",
            "M3 (Random Forest)               100.00      100.00       99.74    99.74   \n",
            "M4 (SVM)                          65.18       63.87       66.49    66.23   \n",
            "M5 (KNN)                          96.07       96.86       95.81    95.55   \n",
            "\n",
            "                          Bootstrap  \n",
            "M1 (Logistic Regression)      91.36  \n",
            "M2 (Decision Tree)            95.55  \n",
            "M3 (Random Forest)            99.21  \n",
            "M4 (SVM)                      76.70  \n",
            "M5 (KNN)                      95.55  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "X = balanced_data.drop('Class', axis=1)\n",
        "y = balanced_data['Class']\n",
        "\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
        "    X, y, test_size=0.25, random_state=42\n",
        ")\n",
        "\n",
        "train_data = pd.concat([X_train_full, y_train_full], axis=1)\n",
        "\n",
        "print(f\"Total Training Data: {len(train_data)}\")\n",
        "print(f\"Total Test Data: {len(X_test)}\")\n",
        "\n",
        "sample_size = min(n, len(train_data))\n",
        "\n",
        "samples = {}\n",
        "samples['Simple Random'] = train_data.sample(n=sample_size, random_state=42)\n",
        "\n",
        "k = int(len(train_data) / sample_size)\n",
        "indices = np.arange(0, len(train_data), k)[:sample_size]\n",
        "samples['Systematic'] = train_data.iloc[indices]\n",
        "\n",
        "samples['Stratified'], _ = train_test_split(\n",
        "    train_data,\n",
        "    train_size=sample_size,\n",
        "    stratify=train_data['Class'],\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "train_data_cluster = train_data.copy()\n",
        "num_clusters = 10\n",
        "train_data_cluster['cluster_id'] = np.random.randint(\n",
        "    0, num_clusters, size=len(train_data)\n",
        ")\n",
        "selected_clusters = np.random.choice(range(num_clusters), size=3, replace=False)\n",
        "cluster_sample = train_data_cluster[\n",
        "    train_data_cluster['cluster_id'].isin(selected_clusters)\n",
        "]\n",
        "samples['Cluster'] = cluster_sample.drop(columns=['cluster_id'])\n",
        "\n",
        "samples['Bootstrap'] = train_data.sample(\n",
        "    n=sample_size, replace=True, random_state=42\n",
        ")\n",
        "\n",
        "models = {\n",
        "    'M1 (Logistic Regression)': LogisticRegression(random_state=42, max_iter=5000),\n",
        "    'M2 (Decision Tree)': DecisionTreeClassifier(random_state=42),\n",
        "    'M3 (Random Forest)': RandomForestClassifier(random_state=42),\n",
        "    'M4 (SVM)': SVC(random_state=42),\n",
        "    'M5 (KNN)': KNeighborsClassifier()\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "print(\"Training on Full Dataset (Baseline)...\")\n",
        "full_scores = {}\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train_full, y_train_full)\n",
        "    acc = accuracy_score(y_test, model.predict(X_test))\n",
        "    full_scores[name] = round(acc * 100, 2)\n",
        "results['No Sampling (Full Data)'] = full_scores\n",
        "\n",
        "for sample_name, sample_df in samples.items():\n",
        "    print(f\"Training on {sample_name}...\")\n",
        "    X_sample = sample_df.drop('Class', axis=1)\n",
        "    y_sample = sample_df['Class']\n",
        "\n",
        "    sample_scores = {}\n",
        "    for name, model in models.items():\n",
        "        model.fit(X_sample, y_sample)\n",
        "        acc = accuracy_score(y_test, model.predict(X_test))\n",
        "        sample_scores[name] = round(acc * 100, 2)\n",
        "    results[sample_name] = sample_scores\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "print(\"\\nAccuracy Comparison Table (%):\")\n",
        "print(results_df)\n",
        "\n",
        "results_df.to_csv(\"sampling_results.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4jWQ36_No3N",
        "outputId": "971e0b3c-5f70-4db7-e047-d3165ccaf0c3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Training Data: 1144\n",
            "Total Test Data: 382\n",
            "Training on Full Dataset (Baseline)...\n",
            "Training on Simple Random...\n",
            "Training on Systematic...\n",
            "Training on Stratified...\n",
            "Training on Cluster...\n",
            "Training on Bootstrap...\n",
            "\n",
            "Accuracy Comparison Table (%):\n",
            "                          No Sampling (Full Data)  Simple Random  Systematic  \\\n",
            "M1 (Logistic Regression)                    91.36          92.15       89.79   \n",
            "M2 (Decision Tree)                          99.48          98.69       99.48   \n",
            "M3 (Random Forest)                         100.00          99.21       99.74   \n",
            "M4 (SVM)                                    67.54          67.02       66.75   \n",
            "M5 (KNN)                                    98.17          95.55       96.07   \n",
            "\n",
            "                          Stratified  Cluster  Bootstrap  \n",
            "M1 (Logistic Regression)       91.10    90.31      92.41  \n",
            "M2 (Decision Tree)             98.17    97.12      96.86  \n",
            "M3 (Random Forest)             99.74    99.21      99.21  \n",
            "M4 (SVM)                       70.16    66.23      66.23  \n",
            "M5 (KNN)                       96.60    93.19      94.76  \n"
          ]
        }
      ]
    }
  ]
}